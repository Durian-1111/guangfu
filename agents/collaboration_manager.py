"""
å¤šæ™ºèƒ½ä½“ååŒç®¡ç†å™¨
åŸºäºLangGraphå®ç°æ™ºèƒ½ä½“ä¹‹é—´çš„ååŒè®¨è®ºå’ŒçŸ¥è¯†èåˆ
"""

# æš‚æ—¶æ³¨é‡Šæ‰LangGraphï¼Œä½¿ç”¨ç®€åŒ–çš„ååŒé€»è¾‘
# from langgraph.graph import StateGraph, END
from typing import Dict, List, Any, TypedDict
import asyncio
import json
from core.llm_client import get_silicon_flow_client
from config import Config

class CollaborationState(TypedDict):
    """ååŒçŠ¶æ€å®šä¹‰"""
    user_query: str
    expert_responses: Dict[str, str]
    collaboration_summary: str
    final_response: str
    current_expert: str

class CollaborationManager:
    def __init__(self):
        self.name = "ååŒè®¨è®ºç®¡ç†å™¨"
        self.experts = {}
        self.llm_client = get_silicon_flow_client()
        
        # åˆå§‹åŒ–ä¸“å®¶æ™ºèƒ½ä½“
        from .cantonese_opera_expert import CantoneseOperaExpert
        from .architecture_expert import ArchitectureExpert
        from .culinary_expert import CulinaryExpert
        from .festival_expert import FestivalExpert
        from .guangfu_ambassador import GuangfuAmbassador
        
        self.experts = {
            "cantonese_opera": CantoneseOperaExpert(),
            "architecture": ArchitectureExpert(),
            "culinary": CulinaryExpert(),
            "festival": FestivalExpert()
        }
        
        # åˆå§‹åŒ–å¹¿åºœæ–‡åŒ–åŠ©æ‰‹
        self.ambassador = GuangfuAmbassador()
        
        # æ„å»ºååŒå·¥ä½œæµ
        self.workflow = self._build_collaboration_workflow()
    
    def _build_collaboration_workflow(self):
        """æ„å»ºååŒå·¥ä½œæµï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰"""
        # æš‚æ—¶è¿”å›Noneï¼Œä½¿ç”¨ç®€åŒ–çš„ååŒé€»è¾‘
        return None
    
    async def start_collaboration(self, user_query: str) -> Dict[str, Any]:
        """å¯åŠ¨å¤šæ™ºèƒ½ä½“ååŒè®¨è®ºï¼ˆæ–°çš„æœ‰åºæµç¨‹ï¼‰"""
        try:
            # ç¬¬ä¸€æ­¥ï¼šå¹¿åºœæ–‡åŒ–åŠ©æ‰‹æ¬¢è¿å¹¶åˆæ­¥å›åº”
            ambassador_initial = await self.ambassador.initial_response(user_query)
            
            # ç¬¬äºŒæ­¥ï¼šå¤§ä½¿åˆ†æå¹¶é€‰æ‹©ç›¸å…³ä¸“å®¶
            selected_experts = self.ambassador.analyze_query_for_experts(user_query)
            
            # ç¬¬ä¸‰æ­¥ï¼šæ”¶é›†ä¸“å®¶å›åº”
            expert_responses = {}
            for expert_name in selected_experts:
                if expert_name in self.experts:
                    try:
                        response = await self.experts[expert_name].process_query(user_query)
                        expert_responses[expert_name] = response
                    except Exception as e:
                        expert_responses[expert_name] = f"{expert_name}æš‚æ—¶æ— æ³•å›åº”ï¼š{str(e)}"
            
            # ç¬¬å››æ­¥ï¼šä¸“å®¶äº’åŠ¨ï¼ˆå¦‚æœæœ‰å¤šä¸ªä¸“å®¶å‚ä¸ï¼‰
            expert_interactions = {}
            if len(expert_responses) > 1:
                for expert_name in selected_experts:
                    if expert_name in self.experts and hasattr(self.experts[expert_name], 'interact_with_other_experts'):
                        try:
                            interaction = await self.experts[expert_name].interact_with_other_experts(
                                user_query, expert_responses
                            )
                            if interaction:  # åªä¿å­˜éç©ºçš„äº’åŠ¨å›åº”
                                expert_interactions[expert_name] = interaction
                        except Exception as e:
                            pass  # äº’åŠ¨å¤±è´¥ä¸å½±å“ä¸»æµç¨‹
            
            # ç¬¬äº”æ­¥ï¼šå¤§ä½¿æ€»ç»“
            final_summary = await self.ambassador.summarize_expert_responses(
                user_query, expert_responses, expert_interactions
            )
            
            return {
                "success": True,
                "user_query": user_query,
                "ambassador_initial": ambassador_initial,
                "selected_experts": selected_experts,
                "expert_responses": expert_responses,
                "expert_interactions": expert_interactions,
                "final_summary": final_summary,
                "participants": ["ambassador"] + selected_experts
            }
            
        except Exception as e:
            return {
                "success": False,
                "error": str(e),
                "fallback_response": "æŠ±æ­‰ï¼ŒååŒè®¨è®ºè¿‡ç¨‹ä¸­å‡ºç°äº†æŠ€æœ¯é—®é¢˜ï¼Œè®©æˆ‘ä¸ºæ‚¨æä¾›åŸºç¡€å›ç­”ã€‚"
            }
    
    async def _analyze_query(self, state: CollaborationState) -> CollaborationState:
        """åˆ†æç”¨æˆ·æŸ¥è¯¢"""
        query = state["user_query"]
        
        # ç®€å•çš„æŸ¥è¯¢åˆ†æ
        analysis = {
            "cultural_domains": [],
            "complexity": "medium",
            "requires_collaboration": True
        }
        
        # æ ¹æ®å…³é”®è¯åˆ¤æ–­æ¶‰åŠçš„æ–‡åŒ–é¢†åŸŸ
        if any(keyword in query for keyword in ["ç²¤å‰§", "æˆæ›²", "è¡¨æ¼”", "å”±è…”"]):
            analysis["cultural_domains"].append("cantonese_opera")
        
        if any(keyword in query for keyword in ["å»ºç­‘", "éª‘æ¥¼", "å›­æ—", "æ°‘å±…"]):
            analysis["cultural_domains"].append("architecture")
        
        if any(keyword in query for keyword in ["ç¾é£Ÿ", "èœç³»", "èŒ¶æ¥¼", "å°åƒ"]):
            analysis["cultural_domains"].append("culinary")
        
        if any(keyword in query for keyword in ["èŠ‚åº†", "æ°‘ä¿—", "ä¼ ç»Ÿ", "åº†å…¸"]):
            analysis["cultural_domains"].append("festival")
        
        # å¦‚æœæ²¡æœ‰æ˜ç¡®é¢†åŸŸï¼Œåˆ™æ¶‰åŠæ‰€æœ‰é¢†åŸŸ
        if not analysis["cultural_domains"]:
            analysis["cultural_domains"] = ["cantonese_opera", "architecture", "culinary", "festival"]
        
        state["analysis"] = analysis
        return state
    
    async def _cantonese_opera_response(self, state: CollaborationState) -> CollaborationState:
        """ç²¤å‰§ä¸“å®¶å›åº”"""
        try:
            response = await self.experts["cantonese_opera"].process_query(state["user_query"])
            state["expert_responses"]["cantonese_opera"] = response
            state["current_expert"] = "cantonese_opera"
        except Exception as e:
            state["expert_responses"]["cantonese_opera"] = f"ç²¤å‰§ä¸“å®¶æš‚æ—¶æ— æ³•å›åº”ï¼š{str(e)}"
        
        return state
    
    async def _architecture_response(self, state: CollaborationState) -> CollaborationState:
        """å»ºç­‘ä¸“å®¶å›åº”"""
        try:
            response = await self.experts["architecture"].process_query(state["user_query"])
            state["expert_responses"]["architecture"] = response
            state["current_expert"] = "architecture"
        except Exception as e:
            state["expert_responses"]["architecture"] = f"å»ºç­‘ä¸“å®¶æš‚æ—¶æ— æ³•å›åº”ï¼š{str(e)}"
        
        return state
    
    async def _culinary_response(self, state: CollaborationState) -> CollaborationState:
        """ç¾é£Ÿä¸“å®¶å›åº”"""
        try:
            response = await self.experts["culinary"].process_query(state["user_query"])
            state["expert_responses"]["culinary"] = response
            state["current_expert"] = "culinary"
        except Exception as e:
            state["expert_responses"]["culinary"] = f"ç¾é£Ÿä¸“å®¶æš‚æ—¶æ— æ³•å›åº”ï¼š{str(e)}"
        
        return state
    
    async def _festival_response(self, state: CollaborationState) -> CollaborationState:
        """èŠ‚åº†ä¸“å®¶å›åº”"""
        try:
            response = await self.experts["festival"].process_query(state["user_query"])
            state["expert_responses"]["festival"] = response
            state["current_expert"] = "festival"
        except Exception as e:
            state["expert_responses"]["festival"] = f"èŠ‚åº†ä¸“å®¶æš‚æ—¶æ— æ³•å›åº”ï¼š{str(e)}"
        
        return state
    
    async def _synthesize_responses(self, state: CollaborationState) -> CollaborationState:
        """ç»¼åˆå„ä¸“å®¶å›åº”"""
        expert_responses = state["expert_responses"]
        
        # æ„å»ºç»¼åˆæ‘˜è¦
        summary_parts = []
        for expert, response in expert_responses.items():
            expert_name = {
                "cantonese_opera": "ç²¤å‰§ä¸“å®¶",
                "architecture": "å»ºç­‘ä¸“å®¶", 
                "culinary": "ç¾é£Ÿä¸“å®¶",
                "festival": "èŠ‚åº†ä¸“å®¶"
            }.get(expert, expert)
            
            summary_parts.append(f"{expert_name}ï¼š{response[:200]}...")
        
        state["collaboration_summary"] = "\n\n".join(summary_parts)
        return state
    
    async def _generate_final_response(self, state: CollaborationState) -> CollaborationState:
        """ç”Ÿæˆæœ€ç»ˆå›åº”"""
        try:
            # æ„å»ºç»¼åˆæ¶ˆæ¯
            messages = [
                {
                    "role": "system", 
                    "content": "ä½ æ˜¯å¹¿åºœéé—æ–‡åŒ–å¤šæ™ºèƒ½ä½“ååŒç³»ç»Ÿçš„ç»¼åˆåˆ†æå¸ˆï¼Œè´Ÿè´£æ•´åˆå„ä¸“å®¶çš„è§‚ç‚¹ï¼Œç”Ÿæˆå…¨é¢ã€è¿è´¯çš„æ–‡åŒ–è§£è¯»ã€‚"
                },
                {
                    "role": "user",
                    "content": f"""åŸºäºä»¥ä¸‹ä¸“å®¶å›åº”ï¼Œä¸ºç”¨æˆ·é—®é¢˜ç”Ÿæˆä¸€ä¸ªç»¼åˆæ€§çš„å›ç­”ï¼š

ç”¨æˆ·é—®é¢˜ï¼š{state['user_query']}

ä¸“å®¶å›åº”ï¼š
{state['collaboration_summary']}

è¯·ç”Ÿæˆä¸€ä¸ªç»¼åˆæ€§çš„å›ç­”ï¼Œæ•´åˆå„ä¸“å®¶çš„è§‚ç‚¹ï¼Œå½¢æˆä¸€ä¸ªå®Œæ•´ã€è¿è´¯çš„å›åº”ã€‚"""
                }
            ]
            
            # è°ƒç”¨ç¡…åŸºæµåŠ¨API - ä¿®å¤ï¼šæ­£ç¡®å¤„ç†å¼‚æ­¥ç”Ÿæˆå™¨
            response_parts = []
            async for chunk in self.llm_client.chat_completion(
                messages=messages,
                model=Config.SILICON_FLOW_MODEL,
                temperature=0.7,
                max_tokens=2000
            ):
                response_parts.append(chunk)
            
            final_response = ''.join(response_parts)
            
            state["final_response"] = final_response
            
        except Exception as e:
            state["final_response"] = f"æŠ±æ­‰ï¼Œåœ¨ç”Ÿæˆæœ€ç»ˆå›åº”æ—¶é‡åˆ°äº†æŠ€æœ¯é—®é¢˜ã€‚å„ä¸“å®¶å›åº”å¦‚ä¸‹ï¼š\n\n{state['collaboration_summary']}"
        
        return state
    
    async def _generate_simple_synthesis(self, user_query: str, expert_responses: Dict[str, str]) -> str:
        """ç”Ÿæˆç®€åŒ–çš„ç»¼åˆå›åº”"""
        try:
            # æ„å»ºç»¼åˆæ¶ˆæ¯
            messages = [
                {
                    "role": "system", 
                    "content": "ä½ æ˜¯å¹¿åºœéé—æ–‡åŒ–å¤šæ™ºèƒ½ä½“ååŒç³»ç»Ÿçš„ç»¼åˆåˆ†æå¸ˆï¼Œè´Ÿè´£æ•´åˆå„ä¸“å®¶çš„è§‚ç‚¹ï¼Œç”Ÿæˆå…¨é¢ã€è¿è´¯çš„æ–‡åŒ–è§£è¯»ã€‚"
                },
                {
                    "role": "user",
                    "content": f"""åŸºäºä»¥ä¸‹ä¸“å®¶å›åº”ï¼Œä¸ºç”¨æˆ·é—®é¢˜ç”Ÿæˆä¸€ä¸ªç»¼åˆæ€§çš„å›ç­”ï¼š

ç”¨æˆ·é—®é¢˜ï¼š{user_query}

ä¸“å®¶å›åº”ï¼š
{json.dumps(expert_responses, ensure_ascii=False, indent=2)}

è¯·ç”Ÿæˆä¸€ä¸ªç»¼åˆæ€§çš„å›ç­”ï¼Œæ•´åˆå„ä¸“å®¶çš„è§‚ç‚¹ï¼Œå½¢æˆä¸€ä¸ªå®Œæ•´ã€è¿è´¯çš„å›åº”ã€‚"""
                }
            ]
            
            # è°ƒç”¨ç¡…åŸºæµåŠ¨API - ä¿®å¤ï¼šæ­£ç¡®å¤„ç†å¼‚æ­¥ç”Ÿæˆå™¨
            response_parts = []
            async for chunk in self.llm_client.chat_completion(
                messages=messages,
                model=Config.SILICON_FLOW_MODEL,
                temperature=0.7,
                max_tokens=2000
            ):
                response_parts.append(chunk)
            
            final_response = ''.join(response_parts)
            
            return final_response
            
        except Exception as e:
            # å¦‚æœç»¼åˆå¤±è´¥ï¼Œè¿”å›ç®€å•çš„ä¸“å®¶å›åº”æ±‡æ€»
            summary_parts = []
            for expert_name, response in expert_responses.items():
                expert_display_name = {
                    'cantonese_opera': 'ç²¤å‰§ä¸“å®¶',
                    'architecture': 'å»ºç­‘ä¸“å®¶',
                    'culinary': 'ç¾é£Ÿä¸“å®¶',
                    'festival': 'èŠ‚åº†ä¸“å®¶'
                }.get(expert_name, expert_name)
                summary_parts.append(f"{expert_display_name}ï¼š{response[:200]}...")
            
            return f"ç»¼åˆå„ä¸“å®¶è§‚ç‚¹ï¼š\n\n" + "\n\n".join(summary_parts)
    
    async def process_query_stream(self, query: str):
        """å¤„ç†å•ä¸ªæŸ¥è¯¢ï¼ˆæµå¼ç‰ˆæœ¬ï¼‰- æ–°çš„æœ‰åºæµç¨‹"""
        try:
            # ç¬¬ä¸€æ­¥ï¼šå¹¿åºœæ–‡åŒ–åŠ©æ‰‹æ¬¢è¿å¹¶åˆæ­¥å›åº”
            yield "ğŸ­ **å¹¿åºœæ–‡åŒ–åŠ©æ‰‹**ï¼š\n"
            async for chunk in self.ambassador.initial_response_stream(query):
                yield chunk
            yield "\n\n"
            
            # ç¬¬äºŒæ­¥ï¼šå¤§ä½¿åˆ†æå¹¶é€‰æ‹©ç›¸å…³ä¸“å®¶
            selected_experts = self.ambassador.analyze_query_for_experts(query)
            
            # ç¬¬ä¸‰æ­¥ï¼šæ”¶é›†ä¸“å®¶å›åº”
            expert_responses = {}
            for expert_name in selected_experts:
                if expert_name in self.experts:
                    expert_display_name = {
                        'cantonese_opera': 'ğŸ­ **ç²¤å‰§ä¸“å®¶æ¢…éŸµå¸ˆå‚…**',
                        'architecture': 'ğŸ›ï¸ **å»ºç­‘ä¸“å®¶çŸ³åŒ è€å¸ˆ**',
                        'culinary': 'ğŸœ **ç¾é£Ÿä¸“å®¶å‘³å¸ˆå‚…**',
                        'festival': 'ğŸŠ **èŠ‚åº†ä¸“å®¶åº†å…¸è€å¸ˆ**'
                    }.get(expert_name, expert_name)
                    
                    yield f"{expert_display_name}ï¼š\n"
                    
                    try:
                        full_response = ""
                        async for chunk in self.experts[expert_name].process_query_stream(query):
                            if chunk is not None:  # ç¡®ä¿chunkä¸ä¸ºNone
                                full_response += chunk
                                yield chunk
                        expert_responses[expert_name] = full_response
                        yield "\n\n"
                    except Exception as e:
                        error_msg = f"{expert_name}æš‚æ—¶æ— æ³•å›åº”ï¼š{str(e)}"
                        expert_responses[expert_name] = error_msg
                        yield error_msg + "\n\n"
            
            # ç¬¬å››æ­¥ï¼šä¸“å®¶äº’åŠ¨ï¼ˆå¦‚æœæœ‰å¤šä¸ªä¸“å®¶å‚ä¸ï¼‰
            if len(expert_responses) > 1:
                yield "ğŸ’¬ **ä¸“å®¶äº’åŠ¨è®¨è®º**ï¼š\n\n"
                
                for expert_name in selected_experts:
                    if expert_name in self.experts and hasattr(self.experts[expert_name], 'interact_with_other_experts_stream'):
                        expert_display_name = {
                            'cantonese_opera': 'ğŸ­ **æ¢…éŸµå¸ˆå‚…è¡¥å……**',
                            'architecture': 'ğŸ›ï¸ **çŸ³åŒ è€å¸ˆè¡¥å……**',
                            'culinary': 'ğŸœ **å‘³å¸ˆå‚…è¡¥å……**',
                            'festival': 'ğŸŠ **åº†å…¸è€å¸ˆè¡¥å……**'
                        }.get(expert_name, expert_name)
                        
                        try:
                            has_interaction = False
                            yield f"{expert_display_name}ï¼š\n"
                            async for chunk in self.experts[expert_name].interact_with_other_experts_stream(
                                query, expert_responses
                            ):
                                if chunk:  # åªè¾“å‡ºéç©ºå†…å®¹
                                    has_interaction = True
                                    yield chunk
                            
                            if has_interaction:
                                yield "\n\n"
                            else:
                                # å¦‚æœæ²¡æœ‰äº’åŠ¨å†…å®¹ï¼Œå›é€€ä¸€è¡Œ
                                yield "\n"
                        except Exception as e:
                            pass  # äº’åŠ¨å¤±è´¥ä¸å½±å“ä¸»æµç¨‹
            
            # ç¬¬äº”æ­¥ï¼šæ–‡åŒ–åŠ©æ‰‹æ€»ç»“
            yield "ğŸ¯ **å¹¿åºœæ–‡åŒ–åŠ©æ‰‹æ€»ç»“**ï¼š\n"
            async for chunk in self.ambassador.summarize_expert_responses_stream(
                query, expert_responses, {}
            ):
                yield chunk
                
        except Exception as e:
            yield f"æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„é—®é¢˜æ—¶é‡åˆ°äº†æŠ€æœ¯é—®é¢˜ï¼š{str(e)}"

    async def process_query(self, query: str) -> str:
        """å¤„ç†å•ä¸ªæŸ¥è¯¢ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰"""
        try:
            # ç®€å•çš„æŸ¥è¯¢å¤„ç†
            if "ååŒ" in query or "è®¨è®º" in query:
                return await self.start_collaboration(query)
            else:
                # é€‰æ‹©æœ€ç›¸å…³çš„ä¸“å®¶
                relevant_expert = self._select_relevant_expert(query)
                return await self.experts[relevant_expert].process_query(query)
        except Exception as e:
            return f"æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„é—®é¢˜æ—¶é‡åˆ°äº†æŠ€æœ¯é—®é¢˜ï¼š{str(e)}"
    
    def _select_relevant_expert(self, query: str) -> str:
        """é€‰æ‹©æœ€ç›¸å…³çš„ä¸“å®¶"""
        # ç®€å•çš„å…³é”®è¯åŒ¹é…
        if any(keyword in query for keyword in ["ç²¤å‰§", "æˆæ›²", "è¡¨æ¼”"]):
            return "cantonese_opera"
        elif any(keyword in query for keyword in ["å»ºç­‘", "éª‘æ¥¼", "å›­æ—"]):
            return "architecture"
        elif any(keyword in query for keyword in ["ç¾é£Ÿ", "èœç³»", "èŒ¶æ¥¼"]):
            return "culinary"
        elif any(keyword in query for keyword in ["èŠ‚åº†", "æ°‘ä¿—", "ä¼ ç»Ÿ"]):
            return "festival"
        else:
            return "cantonese_opera"  # é»˜è®¤é€‰æ‹©ç²¤å‰§ä¸“å®¶
